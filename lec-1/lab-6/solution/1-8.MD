### Задача 1

Порядок в котором пронумерованы векторы признаков, влияет на процесс обучения перцептрона. Алгоритм перцептрона работает последовательно, обновляя веса на каждом шаге для одного образца -> если образцы подаются в другом порядке, это может изменить траекторию обновления весов. 

Однако по теореме сходимости перцептрона => если данные линейно разделимы, то алгоритм всегда сойдется к решению, независимо от порядка образцов. Поэтому порядок влияет на конкретный путь к решению, но не на конечный результат в случае линейно разделимых данных.

### Задача 2

Алгоритм обучения перцептрона обновляет веса таким образом:

$w_{t+1} = w_t + \eta y^{(k)} x^{(k)}$

где $\eta$ — коэффициент обучения, $x^{(k)}$ - обучающий пример, $y^{(k)}$ — его метка. 

При больших значениях $\eta$ шаг обновления больше, и алгоритм быстрее достигает разделяющей гиперплоскости, если данные линейно разделимы. 

Однако при уменьшении $\eta$ шаг обновления становится меньше,что займет больше итераций, так как веса изменяются медленнее.

Но сходимость будет иметь место также и при меньших значениях $\eta$, но потребуется большее количество итераций для достижения решения. 

### Задача 3

Рассмотрим ситуацию, когда в процессе обучения встречаются промежуточные итерации, на которых классификация производится верно, но выбираемые из выборки векторы признаков принадлежат классу $(\mathcal{H}_2)$. Тогда в таком этом случае алгоритм не обновляет веса, так как классификация верна => текущие веса остаются неизменными.

Доказательство сходимости перцептрона основано на том, что на каждой итерации, когда классификация производится неверно, веса обновляются в направлении, уменьшающем ошибку. 

- Если вектор классифицирован верно, веса не меняются, что не мешает сходимости, так как алгоритм все равно продолжает обрабатывать последующие образцы. 

Таким образом, если данные линейно разделимы, то перцептрон корректно классифицирует все примеры и достигнет сходимости. Поэтому доказательство сходимости алгоритма сохраняется в силе, даже если промежуточные результаты включают правильную классификацию образцов из класса $(\mathcal{H}_2)$.


### Задача 4

#### Дано
- Обучающая выборка состоит из одного элемента {x, +1}.
- Начальные значения весов w выбираются случайно на интервале [0, 1].
- Нужно оценить среднее количество неверных классификаций подряд при выполнении алгоритма обучения.
- Показать, что оно зависит от нормы вектора |x|
- Также что чем меньше коэффициент обучения, тем больше это количество.

Перцептрон обновляет веса \(w\) следующим образом: $w_{t+1} = w_t + \eta y x$

где:
- w_t — вектор весов на t-й итерации,
- $\eta$ — коэффициент обучения,
- (y = +1) — метка класса,
- x — вектор признаков.

Так как y = +1, правило обновления весов принимает вид: $w_{t+1} = w_t + \eta x$

----

Неверная классификация происходит, если $( w_t^T x \leq 0 )$. На каждой итерации вес обновляется, увеличивая $( w_t^T x)$ на $(\eta |x\|^2)$.

----

Среднее количество неверных классификаций. 

Чтобы оценить количество неверных классификаций, рассмотрим обновление весов и изменение скалярного произведения $(w_t^T x)$ на каждой итерации. Обновление весов увеличивает скалярное произведение: $w_{t+1}^T x = (w_t + \eta x)^T x = w_t^T x + \eta \|x\|^2$

На каждой итерации значение $(w_t^T x)$ увеличивается на величину $(\eta \|x\|^2)$ => если начальное значение $(w_0^T x \leq 0)$, то потребуется несколько итераций, чтобы $(w_t^T x > 0)$.

Среднее количество неверных классификаций можно оценить как: $T = \frac{-w_0^T x}{\eta \|x\|^2}$

Так как $(w_0)$ выбирается случайным образом из интервала \([0, 1]\), то значение $(w_0^T x)$ тоже случайно. В среднем оно будет около 1/2 max значения.

Таким образом, среднее количество неверных классификаций:
$T \approx \frac{0.5 \|x\|}{\eta \|x\|^2} = \frac{0.5}{\eta \|x\|}$

----

Зависимость от нормы $(\|x\|)$ и коэффициента обучения $(\eta)
Из полученной формулы можно сделать следующие выводы:

- Чем больше норма вектора $(\|x\|)$, тем меньше количество неверных классификаций. 
  
- Чем меньше $(\eta)$, тем больше среднее количество неверных классификаций: при малом $(\eta)$ шаг обновления весов на каждой итерации меньше, и требуется большее количество итераций, чтобы исправить неверную классификацию.


Таким образом, уменьшение коэффициента обучения приводит к увеличению среднего количества неверных классификаций, а увеличение нормы вектора $(\|x\|)$ — к его уменьшению.


### Задача 5

Если функция активации линейная, например, $( f(x) = ax + b)$, то выход каждого нейрона является линейной комбинацией входов. 

Когда сеть состот из нескольких слоев, каждый последующий слой также является линейной комбинацией предыдущего. Таким образом составное преобразование всей сети остается линейным. можно представить преобрзование всей сети как матричное умножжение одного слоя на следующий, что также дает линейную фнкцию.

### Задача 6
Когда количество скрытых узлов меньше числа входов или выходов, сеть фактичеки сжимает размерность данных. 

Например, при преобразовании через матрицу с меньшим числом строк, чем количество входных элементов, результирующее пространтсво имеет меньшую размерность. 

как вывод, при использовании линейных функций активации и меньшего числа узлов в скрытых слоях преобразование фактически является сжатием размерности, что приводит к потере информации.

### Задача 7

Если в сети используются линейные функции активации и возможны прямые связи межлу любыми слоями, то такое соединение можно рассматривать как эквивалетное многослойному перцептрону, где все слои обьединены в один матричный оператор. Поскльку линейная комбинация линейных функций также является линейной, весь многослойный персептрон можно свернуть в один линейный слой. Такм образом, такая сеть не отличается от многослойного перцептрона с линейными функциями активации.


### Задача 8

1. Производная логистического сигмоида $\sigma(x)$ вычисляется как:
   $\sigma(x) = \frac{1}{1 + e^{-x}}$
   Производная: $\sigma'(x) = \sigma(x) (1 - \sigma(x))$

2. Производная гиперболического тангенса $\tanh(x)$:
   = $\frac{e^x - e^{-x}}{e^x + e^{-x}}$
   Производная: $\tanh'(x)$ = $1 - \tanh^2(x)$


- Оба выражения для производных логистического сигмоида и гиперболического тангенса зависят от значения самой функции что упрощает вычесления при обратном распространеии ошибки.
- Значения производных находятся в диапазоне от 0 до 1 что помогает избежать проблем с нестабильностю градиентов, таких как взрыв градиетов или их исчезновение. Это делает обучение нейронной сети более стабильным.